{
  "hash": "ff35fddf6f67d72f3fbc7a4d6991eaaf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: DuckDB SQL\nsubtitle: Use the same queries from R, Python, Julia...\nexecute:\n  freeze: auto\n  cache: true\n---\n\n\n\n\n## Load libraries\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(duckdb)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: DBI\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport duckdb\nimport time # just for timing some queries\n```\n:::\n\n\n:::\n\n## Create a database connection\n\nThe first thing we need to do is instantiate a connection with an _in-memory_\ndatabase.^[Aside: The `shutdown = TRUE` argument is a convenience feature that\nensures our connection is automatically terminated when our R session ends\n(i.e., even if we forget to do it manually.) I'm not aware of a similar\nconvenience argument for Python; please let me know if I am missing something.]\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon = dbConnect(duckdb(), shutdown = TRUE)\n```\n:::\n\n\n### Python \n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon = duckdb.connect(database = ':memory:', read_only = False)\n```\n:::\n\n\n:::\n\n#### Digression: In-memory versus on-disk\n\nThe fact that our connection lives \"in memory\" is a killer feature of DuckDB (one\nthat it inherits from SQLite). We don't need to connect to some complicated,\nexisting database infrastructure to harness all of DuckDB's power. Instead we can just spin up\nan ephemeral database that interacts directly with our R (or Python, or Julia,\netc.) client.\n\nHowever, it's worth noting that you _can_ create a persistent,\ndisk-backed database simply by providing a database file path argument as part\nof your connection, e.g.\n\n::: {.panel-tabset}\n\n### R\n\n```r\n## Uncomment and run the next line if you'd like to create a persistent,\n## disk-backed database instead.\n\n# con = dbConnect(duckdb(), dbdir = \"nyc.duck\")\n```\n\n### Python \n\n```python\n## Uncomment and run the next line if you'd like to create a persistent,\n## disk-backed database instead.\n\n# con = duckdb.connect(database = 'nyc.duck', read_only = False)\n```\n\n:::\n\n\n(Note that the `\".duck\"` file extension above is optional. You could also use `\".db\"`, `\".dbb\"`, or whatever you want really.)\n\n:::{.callout-important}\n## Bigger than RAM data?\nOne really important benefit of creating a persistent disk-backed database is\nthat it enables out-of-core computation for bigger than RAM data. See\n[here](https://duckdb.org/2024/03/29/external-aggregation.html) for more details\nand performance considerations (which are still great).\n:::\n\n## First example\n\nWe'll start with a simple aggregation query to get situated. I'll also use\nthis example to highlight some general features of DuckDB SQL and\nthe underlying query engine.\n\nOkay, first query. Let's say we want to know: _What is the average tip per\npassenger count?_ A typical SQL job for this question might look as follows:\n\n```sql\nSELECT\n  passenger_count,\n  AVG(tip_amount) AS mean_tip\nFROM 'nyc-taxi/**/*.parquet'\nGROUP BY passenger_count\nORDER BY passenger_count\n```\n\n(Where the last `ORDER BY` statement is optional. Note that ordering (i.e.,\nsorting) is a potentially expensive operation but we'll get back to that later.)\n\nThis is perfectly valid DuckDB SQL too. However, we can rewrite it with slightly\nnicer syntax thanks DuckDB's\n\"[friendly SQL](https://duckdb.org/docs/guides/sql_features/friendly_sql)\". The \nkey changes for this simple query are going to be: (1) the `FROM` statement\ncomes first, and (2) we can use the `GROUP BY ALL` and `ORDER BY ALL` statements to avoid writing out\nthe \"passenger_count\" grouping column multiple times.^[I'll admit that the benefits don't\nseem so great for this simple example. But trust me: they make a big difference\nonce you start having lots of grouping columns and complex sub-queries.]\n\n```sql\nFROM 'nyc-taxi/**/*.parquet'\nSELECT\n  passenger_count,\n  AVG(tip_amount) AS mean_tip\nGROUP BY ALL\nORDER BY ALL\n```\n\n:::{.callout-tip}\n### DuckDB's \"friendly SQL\"\nOne of the under-appreciated (IMHO) features of DuckDB is that it supports many\nsyntax enhancements over tradional SQL dialects, which they collectively dub\n\"[friendly SQL](https://duckdb.org/docs/guides/sql_features/friendly_sql)\".\nTogether these syntax enhancements allow you to write much more ergonomic SQL\nqueries that cut down on duplication and logical inconsistencies.\n:::\n\nTo run this operation from our R or Python client, simply pass the SQL query as\na string to our connection. Let's use this as a chance to save the result and\ntime our query too. \n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic = Sys.time()\ndat1 = dbGetQuery(\n  con,\n  \"\n  FROM 'nyc-taxi/**/*.parquet'\n  SELECT\n    passenger_count,\n    AVG(tip_amount) AS mean_tip\n  GROUP BY ALL\n  ORDER BY ALL\n  \"\n)\ntoc = Sys.time()\n\ndat1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   passenger_count  mean_tip\n1                0 0.8620988\n2                1 1.1510110\n3                2 1.0815798\n4                3 0.9629494\n5                4 0.8445190\n6                5 1.1027325\n7                6 1.1283649\n8                7 0.5441176\n9                8 0.3507692\n10               9 0.8068000\n11              10 0.0000000\n12              65 0.0000000\n13              66 1.5000000\n14             177 1.0000000\n15             208 0.0000000\n16             247 2.3000000\n17             249 0.0000000\n18             254 0.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc - tic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 1.211972 secs\n```\n\n\n:::\n:::\n\n\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntic = time.time()\ndat1 = (\n  con.\n  query(\n    '''\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      passenger_count,\n      AVG(tip_amount) AS mean_tip\n    GROUP BY ALL\n    ORDER BY ALL\n    '''\n    )\n)\ntoc = time.time()\n\ndat1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌─────────────────┬─────────────────────┐\n│ passenger_count │      mean_tip       │\n│      int64      │       double        │\n├─────────────────┼─────────────────────┤\n│               0 │  0.8620988141424404 │\n│               1 │  1.1510109615454076 │\n│               2 │  1.0815798424001326 │\n│               3 │  0.9629493657892962 │\n│               4 │  0.8445189789660359 │\n│               5 │   1.102732453261797 │\n│               6 │  1.1283649236954338 │\n│               7 │  0.5441176470588235 │\n│               8 │ 0.35076923076923083 │\n│               9 │  0.8068000000000001 │\n│              10 │                 0.0 │\n│              65 │                 0.0 │\n│              66 │                 1.5 │\n│             177 │                 1.0 │\n│             208 │                 0.0 │\n│             247 │                 2.3 │\n│             249 │                 0.0 │\n│             254 │                 0.0 │\n├─────────────────┴─────────────────────┤\n│ 18 rows                     2 columns │\n└───────────────────────────────────────┘\n```\n\n\n:::\n\n```{.python .cell-code}\n# print(f\"Time difference of {toc - tic} seconds\")\n## Timing will be misleading for this rendered Quarto doc, since we're calling\n## Python from R (via the reticulate package).\n```\n:::\n\n\nNote that we actually get a **polars** DataFrame as a return object. Click the\ncallout box below to learn more.\n\n::::{.callout-note collapse=\"true\"}\n## Result conversion in Python (click to expand)\nBy default, the `con.query` method that we are using here will return a\n**polars** DataFrame object that Python understands \"natively\" (i.e., has a\nprint method for and so on). Behind the scenes, this **duckdb** to **polars**\nintegration relies on the **pyarrow** library being available to our Python\nenvironment, which have already installed for this workshop.\n\nIt's also possible return other types of Python objects. For example, you can\nuse the `.df()` method to coerce to a **pandas** DataFrame instead, among\nseveral other formats like **numpy** arrays. (Details\n[here](https://duckdb.org/docs/api/python/overview#result-conversion).) Given\nthe focus of this workshop, it won't surprise you to hear that I'm going to\nstick with the default **polars** conversion.\n::::\n\n:::\n\nSo that only took 1.21 seconds in this rendered Quarto doc (and will\nlikely be even faster when you try in an interactive session). To underscore\njust how crazy impressive this is, recall that this **includes the time that it\ntakes to read the data from disk**. I can almost guarantee that the read +\nserialization time alone for traditional data wrangling workflows would take\nseveral minutes, and probably crash my laptop RAM. Don't forget that our full\ndataset is nearly 200 million rows deep and 30 columns wide.\n\n_Aside: We clearly have a few outlier typos in our dataset. 254 passengers in a\nsingle taxi trip? I don't think so. We'd probably want to filter these out with\na `WHERE` statement if we were doing serious analysis, but I'm just going to\nleave them in for this tutorial._\n\n\n## Aggregation\n\nLet's try out some more aggregation queries. How about a slightly variation on a our first example query, where we (a) add \"month\" as a second grouping variable, and (b) subset to only the first\nthree months of the year. \n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic = Sys.time()\ndat2 = dbGetQuery(\n  con,\n  \"\n  FROM 'nyc-taxi/**/*.parquet'\n  SELECT\n    month,\n    passenger_count,\n    AVG(tip_amount) AS mean_tip\n  WHERE month <= 3\n  GROUP BY ALL\n  \"\n    )\ntoc = Sys.time()\n\nhead(dat2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  month passenger_count mean_tip\n1     1               1 1.036863\n2     2               1 1.068490\n3     3               1 1.089205\n4     2               8 0.500000\n5     1               8 0.000000\n6     1               7 0.000000\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc - tic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 0.373965 secs\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntic = time.time()\ndat2 = (\n  con.\n  query(\n    '''\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      month,\n      passenger_count,\n      AVG(tip_amount) AS mean_tip\n    WHERE month <= 3\n    GROUP BY ALL\n    '''\n  )\n)\ntoc = time.time()\n\ndat2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌───────┬─────────────────┬────────────────────┐\n│ month │ passenger_count │      mean_tip      │\n│ int64 │      int64      │       double       │\n├───────┼─────────────────┼────────────────────┤\n│     1 │               8 │                0.0 │\n│     2 │               8 │                0.5 │\n│     1 │               7 │                0.0 │\n│     1 │               3 │ 0.8752659692390742 │\n│     1 │               6 │ 1.0175694433120148 │\n│     2 │               3 │ 0.8948976704752726 │\n│     2 │               6 │ 1.0218459360559857 │\n│     3 │               6 │ 1.0515659390082825 │\n│     3 │               3 │ 0.9121818858010082 │\n│     1 │               1 │ 1.0368628142310818 │\n│     · │               · │          ·         │\n│     · │               · │          ·         │\n│     · │               · │          ·         │\n│     2 │               2 │ 0.9908003546925661 │\n│     3 │               2 │ 1.0096468528132252 │\n│     3 │             208 │                0.0 │\n│     1 │             208 │                0.0 │\n│     1 │               5 │  1.001198485873298 │\n│     2 │               5 │ 1.0157674270380461 │\n│     3 │               5 │ 1.0353911898062576 │\n│     1 │              65 │                0.0 │\n│     2 │               9 │                0.0 │\n│     1 │               9 │                0.0 │\n├───────┴─────────────────┴────────────────────┤\n│ 29 rows (20 shown)                 3 columns │\n└──────────────────────────────────────────────┘\n```\n\n\n:::\n\n```{.python .cell-code}\n# print(f\"Time difference of {toc - tic} seconds\")\n## Timing will be misleading for this rendered Quarto doc, since we're calling\n## Python from R (via the reticulate package).\n```\n:::\n\n\n:::\n\nNote that this query completed even faster than the first one, even though we\nadded another grouping variable. Reason: Subsetting along our Hive-partitioned\nparquet dataset allows DuckDB to take shortcuts. We can see this directly by\nprepending an `EXPLAIN` statement to our query to reveal the optmized query\nplan.\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbGetQuery(\n  con,\n  \"\n  EXPLAIN\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      month,\n      passenger_count,\n      AVG(tip_amount) AS mean_tip\n    WHERE month <= 3\n    GROUP BY ALL\n  \"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nphysical_plan\n┌───────────────────────────┐\n│       HASH_GROUP_BY       │\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\n│             #0            │\n│             #1            │\n│          avg(#2)          │\n└─────────────┬─────────────┘                             \n┌─────────────┴─────────────┐\n│         PROJECTION        │\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\n│           month           │\n│      passenger_count      │\n│         tip_amount        │\n└─────────────┬─────────────┘                             \n┌─────────────┴─────────────┐\n│       PARQUET_SCAN        │\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\n│           month           │\n│      passenger_count      │\n│         tip_amount        │\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\n│ File Filters: (month <= 3)│\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\n│        EC: 44907396       │\n└───────────────────────────┘                             \n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.query(\n  '''\n  EXPLAIN\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      month,\n      passenger_count,\n      AVG(tip_amount) AS mean_tip\n    WHERE month <= 3\n    GROUP BY ALL\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌───────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────┐\n│  explain_key  │                                            explain_value                                             │\n│    varchar    │                                               varchar                                                │\n├───────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────┤\n│ physical_plan │ ┌───────────────────────────┐\\n│       HASH_GROUP_BY       │\\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\\n│    …  │\n└───────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────┘\n```\n\n\n:::\n:::\n\n\n:::\n\n_tl;dr_ DuckDB is able to exploit the month partition of our dataset, so\nsubsetting means that it can avoid unecessary data ingestion. Similarly, it only\nreads in a select group of columns; that's what the \"PROJECTION\" part of the\nplan denotes. If nothing else, the take-home message is that DuckDB only does\nwhat it needs to. Laziness as a virtue!\n\nHere's a final aggregation example, this time including a high-dimensional\ngrouping column (i.e., \"trip_distance\") and some additional aggregations.\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic = Sys.time()\ndat3 = dbGetQuery(\n  con,\n  \"\n  FROM 'nyc-taxi/**/*.parquet'\n  SELECT\n    passenger_count,\n    trip_distance,\n    AVG(tip_amount) AS mean_tip,\n    AVG(fare_amount) AS mean_fare\n  GROUP BY ALL\n\"\n)\ntoc = Sys.time()\n\nnrow(dat3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25569\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(dat3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  passenger_count trip_distance  mean_tip mean_fare\n1               1          3.80 1.4617821 13.624269\n2               1          2.70 1.1625732 10.811488\n3               1          2.20 1.0099496  9.471702\n4               1          4.70 1.6794478 15.728522\n5               2          1.86 0.8184262  8.482737\n6               2          2.70 0.9988106 10.910493\n```\n\n\n:::\n\n```{.r .cell-code}\ntoc - tic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 2.870613 secs\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntic = time.time()\ndat3 = (\n  con.\n  query(\n    '''\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      passenger_count,\n      trip_distance,\n      AVG(tip_amount) AS mean_tip,\n      AVG(fare_amount) AS mean_fare\n    GROUP BY ALL\n    '''\n    )\n)\ntoc = time.time()\n\nlen(dat3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n25569\n```\n\n\n:::\n\n```{.python .cell-code}\ndat3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌─────────────────┬───────────────┬─────────────────────┬────────────────────┐\n│ passenger_count │ trip_distance │      mean_tip       │     mean_fare      │\n│      int64      │    double     │       double        │       double       │\n├─────────────────┼───────────────┼─────────────────────┼────────────────────┤\n│               1 │           2.7 │    1.16257323977722 │ 10.811487937005044 │\n│               1 │           8.5 │  3.0037572144209994 │ 23.762548777891176 │\n│               2 │           2.7 │  0.9988105937071349 │ 10.910492532335036 │\n│               1 │           1.8 │   0.878870484195116 │  8.402046190257858 │\n│               1 │           0.2 │  0.3864478915075284 │  4.671192577145984 │\n│               1 │           5.9 │  1.9316437836686586 │   18.4181575160648 │\n│               1 │           9.8 │   3.602063841563186 │  26.75012573394927 │\n│               1 │           4.7 │   1.679447806444995 │ 15.728522049844514 │\n│               1 │           2.2 │   1.009949551490608 │   9.47170239542306 │\n│               1 │          0.93 │  0.5659718504077408 │ 5.8204754998691905 │\n│               · │            ·  │           ·         │          ·         │\n│               · │            ·  │           ·         │          ·         │\n│               · │            ·  │           ·         │          ·         │\n│               5 │           3.2 │   1.213120921023685 │ 12.059595218889795 │\n│               2 │          4.58 │  1.5289010022859153 │  15.32215579391595 │\n│               3 │          1.34 │  0.6439547586916009 │  6.937227684596117 │\n│               5 │          0.69 │  0.4423211070274535 │  4.844665893786588 │\n│               1 │         17.93 │   4.768273278630039 │ 48.079521940777724 │\n│               6 │          0.49 │ 0.36281714343475185 │    4.2202365308804 │\n│               6 │          1.53 │  0.7403351611114536 │  7.555714373729288 │\n│               1 │         18.06 │   4.738210227272728 │ 48.059339488636354 │\n│               5 │          13.6 │  3.7402173913043484 │  36.93664596273292 │\n│               1 │         12.75 │   3.638386937159822 │  34.57689262741217 │\n├─────────────────┴───────────────┴─────────────────────┴────────────────────┤\n│ ? rows (>9999 rows, 20 shown)                                    4 columns │\n└────────────────────────────────────────────────────────────────────────────┘\n```\n\n\n:::\n\n```{.python .cell-code}\n# print(f\"Time difference of {toc - tic} seconds\")\n## Timing will be misleading for this rendered Quarto doc, since we're calling\n## Python from R (via the reticulate package).\n```\n:::\n\n\n:::\n\n## Pivot (reshape)\n\nLet's explore some pivot (reshape) examples, by building off the previous query.\n\n- `UNPIVOT`: wide => long\n- `PIVOT`: long => wide\n\nHere I'll use a\n[Common Table Expression (CTE)](https://raw.githack.com/uo-ec607/lectures/master/16-databases/16-databases.html#Common_Table_Expressions)\nto define a temporary table `tmp_table`, before unpivoting---i.e., reshaping\nlong---at the\nend.\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_long = dbGetQuery(\n  con,\n  \"\n  WITH tmp_table AS (\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      passenger_count,\n      trip_distance,\n      AVG(tip_amount) AS mean_tip,\n      AVG(fare_amount) AS mean_fare\n    GROUP BY ALL\n  )\n  UNPIVOT tmp_table\n  ON mean_tip, mean_fare\n  INTO\n    NAME variable\n    VALUE amount\n  \"\n)\n\nhead(dat_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  passenger_count trip_distance  variable     amount\n1               1           1.1  mean_tip  0.6530588\n2               1           1.1 mean_fare  6.3333552\n3               2          18.0  mean_tip  3.7746336\n4               2          18.0 mean_fare 48.1438661\n5               1           1.2  mean_tip  0.6882080\n6               1           1.2 mean_fare  6.6407479\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndat_long = (\n  con.\n  query(\n    '''\n    WITH tmp_table AS (\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        passenger_count,\n        trip_distance,\n        AVG(tip_amount) AS mean_tip,\n        AVG(fare_amount) AS mean_fare\n      GROUP BY ALL\n    )\n    UNPIVOT tmp_table\n    ON mean_tip, mean_fare\n    INTO\n      NAME variable\n      VALUE amount\n    '''\n  )\n)\n\ndat_long\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌─────────────────┬───────────────┬───────────┬────────────────────┐\n│ passenger_count │ trip_distance │ variable  │       amount       │\n│      int64      │    double     │  varchar  │       double       │\n├─────────────────┼───────────────┼───────────┼────────────────────┤\n│               1 │           0.9 │ mean_tip  │  0.578974821777743 │\n│               1 │           0.9 │ mean_fare │  5.687595795787245 │\n│               1 │          11.1 │ mean_tip  │  3.839358215996518 │\n│               1 │          11.1 │ mean_fare │ 29.974972782697066 │\n│               1 │           4.0 │ mean_tip  │ 1.5167455372913883 │\n│               1 │           4.0 │ mean_fare │ 14.098943870659395 │\n│               1 │          17.3 │ mean_tip  │  5.590380869171258 │\n│               1 │          17.3 │ mean_fare │ 47.364542924635145 │\n│               1 │          0.71 │ mean_tip  │ 0.4766168470138103 │\n│               1 │          0.71 │ mean_fare │  5.104461268390179 │\n│               · │            ·  │    ·      │           ·        │\n│               · │            ·  │    ·      │           ·        │\n│               · │            ·  │    ·      │           ·        │\n│               5 │          12.7 │ mean_tip  │   3.07948347107438 │\n│               5 │          12.7 │ mean_fare │  33.64896694214877 │\n│               2 │         12.25 │ mean_tip  │ 3.1529553264604813 │\n│               2 │         12.25 │ mean_fare │  32.42886597938145 │\n│               6 │          9.22 │ mean_tip  │  3.173150684931507 │\n│               6 │          9.22 │ mean_fare │ 25.668340943683408 │\n│               6 │          9.34 │ mean_tip  │ 2.8852453987730065 │\n│               6 │          9.34 │ mean_fare │  25.80444785276073 │\n│               1 │          33.5 │ mean_tip  │  5.801387283236995 │\n│               1 │          33.5 │ mean_fare │  56.67167630057804 │\n├─────────────────┴───────────────┴───────────┴────────────────────┤\n│ ? rows (>9999 rows, 20 shown)                          4 columns │\n└──────────────────────────────────────────────────────────────────┘\n```\n\n\n:::\n:::\n\n\n:::\n\nAnother option would have been to create a new table in memory\nand then pivot over that, which segues nicely to...\n\n### Digression: Create new tables\n\nCTEs are a very common, and often efficient, way to implement multi-table\noperations in SQL. But, for the record, we can create new tables in DuckDB's\nmemory cache pretty easily using the `CREATE TABLE` statement.\n\n::: {.panel-tabset}\n\n### R\n\nInstead of `DBI::dbGetQuery`, we must now use `DBI::dbExecute`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbExecute(\n    con,\n    \"\n    CREATE TABLE taxi2 AS\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        passenger_count,\n        trip_distance,\n        AVG(tip_amount) AS mean_tip,\n        AVG(fare_amount) AS mean_fare\n      GROUP BY ALL\n    \"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 25569\n```\n\n\n:::\n\n```{.r .cell-code}\ndbListTables(con)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"taxi2\"\n```\n\n\n:::\n:::\n\n\nFWIW, you can always remove a table with `dbRemoveTable()`.\n\n### Python \n\nInstead of `con.query()`, we must now use `con.execute()`.\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.execute(\n  '''\n  CREATE TABLE taxi2 AS\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      passenger_count,\n      trip_distance,\n      AVG(tip_amount) AS mean_tip,\n      AVG(fare_amount) AS mean_fare\n    GROUP BY ALL\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<duckdb.duckdb.DuckDBPyConnection object at 0x1062d3cb0>\n```\n\n\n:::\n\n```{.python .cell-code}\n# https://stackoverflow.com/q/75727685\ncon.query(\n  '''\n  SELECT table_name, estimated_size AS nrows, column_count AS ncols\n  FROM duckdb_tables;\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌────────────┬───────┬───────┐\n│ table_name │ nrows │ ncols │\n│  varchar   │ int64 │ int64 │\n├────────────┼───────┼───────┤\n│ taxi2      │ 25569 │     4 │\n└────────────┴───────┴───────┘\n```\n\n\n:::\n:::\n\n:::\n\n### Back to reshaping\n\nWith our new `taxi2` table in hand, let's redo the previous unpivot query\ndirectly on this new table. This makes the actual (un)pivot statement a bit\nclearer... and also separates out the execution time.\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbGetQuery(\n  con,\n  \"\n  UNPIVOT taxi2\n  ON mean_tip, mean_fare\n  INTO\n    NAME variable\n    VALUE amount\n  LIMIT 5\n  \"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  passenger_count trip_distance  variable    amount\n1               1           1.1  mean_tip 0.6530588\n2               1           1.1 mean_fare 6.3333552\n3               1           1.2  mean_tip 0.6882080\n4               1           1.2 mean_fare 6.6407479\n5               1           1.3  mean_tip 0.7207278\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.query(\n  '''\n  UNPIVOT taxi2\n  ON mean_tip, mean_fare\n  INTO\n    NAME variable\n    VALUE amount\n  LIMIT 5\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌─────────────────┬───────────────┬───────────┬────────────────────┐\n│ passenger_count │ trip_distance │ variable  │       amount       │\n│      int64      │    double     │  varchar  │       double       │\n├─────────────────┼───────────────┼───────────┼────────────────────┤\n│               1 │           2.7 │ mean_tip  │   1.16257323977722 │\n│               1 │           2.7 │ mean_fare │  10.81148793700505 │\n│               0 │           9.1 │ mean_tip  │  2.399264497878359 │\n│               0 │           9.1 │ mean_fare │ 23.355728429985852 │\n│               1 │           1.8 │ mean_tip  │ 0.8788704841951157 │\n└─────────────────┴───────────────┴───────────┴────────────────────┘\n```\n\n\n:::\n:::\n\n\n:::\n\n(Note how crazy fast pivoting in DuckDB actually is.)\n\n## Joins (merges)\n\nIt's a bit hard to demonstrate a join with only a single main table. But here is\na contrived example, where we calculate the mean monthly tips and the mean\nmonthly fares as separate sub-queries (CTEs), before joining them together by\nmonth.\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbGetQuery(\n  con,\n  \"\n  WITH \n    mean_tips AS (\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        month,\n        AVG(tip_amount) AS mean_tip\n      GROUP BY month\n    ),\n    mean_fares AS (\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        month,\n        AVG(fare_amount) AS mean_fare\n      GROUP BY month \n    )\n  FROM mean_tips\n  LEFT JOIN mean_fares\n  USING (month)\n  SELECT *\n  ORDER BY mean_tips.month\n  \"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   month mean_tip mean_fare\n1      1 1.007817  9.813488\n2      2 1.036874  9.942640\n3      3 1.056353 10.223107\n4      4 1.043167 10.335490\n5      5 1.078014 10.585157\n6      6 1.091082 10.548651\n7      7 1.059312 10.379943\n8      8 1.079521 10.492650\n9      9 1.254601 12.391198\n10    10 1.281239 12.501252\n11    11 1.250903 12.270138\n12    12 1.237651 12.313953\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.query(\n  '''\n  WITH \n    mean_tips AS (\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        month,\n        AVG(tip_amount) AS mean_tip\n      GROUP BY month\n    ),\n    mean_fares AS (\n      FROM 'nyc-taxi/**/*.parquet'\n      SELECT\n        month,\n        AVG(fare_amount) AS mean_fare\n      GROUP BY month \n    )\n  FROM mean_tips\n  LEFT JOIN mean_fares\n  USING (month)\n  SELECT *\n  ORDER BY mean_tips.month\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌───────┬────────────────────┬────────────────────┐\n│ month │      mean_tip      │     mean_fare      │\n│ int64 │       double       │       double       │\n├───────┼────────────────────┼────────────────────┤\n│     1 │ 1.0078165246989366 │  9.813487671828813 │\n│     2 │ 1.0368737381553987 │  9.942640301300228 │\n│     3 │   1.05635274287244 │ 10.223107216153554 │\n│     4 │ 1.0431674901411208 │ 10.335489610549338 │\n│     5 │ 1.0780143169836092 │ 10.585156844134143 │\n│     6 │  1.091082009381275 │ 10.548651231531922 │\n│     7 │  1.059312239456315 │ 10.379943069577804 │\n│     8 │ 1.0795208991227114 │ 10.492650001890153 │\n│     9 │ 1.2546008978994332 │ 12.391197540031698 │\n│    10 │ 1.2812392796882088 │ 12.501252484194163 │\n│    11 │ 1.2509031985269687 │ 12.270137514944446 │\n│    12 │ 1.2376507362291407 │ 12.313952857613234 │\n├───────┴────────────────────┴────────────────────┤\n│ 12 rows                               3 columns │\n└─────────────────────────────────────────────────┘\n```\n\n\n:::\n:::\n\n\n:::\n\n:::{.callout-tip}\n## Challenge\n\nRedo the above join but, rather than using CTEs, use tables that you first\ncreate in DuckDB's memory bank. Again, this will simplify the actual join\noperation and also emphasise how crazy fast joins are in DuckDB.\n:::\n\n## Windowing\n\nOne last example: Binning \"trip_distance\" into deciles and then calculating the\nthe mean \"tip_amount\" within each decile. This is an example of a\n[window function](https://duckdb.org/2021/10/13/windowing.html)\nand query pattern that I use _all the time_ in my own work. I find it extremely\nuseful for quickly pulling out descriptive patterns from large datasets, from\nwhich I can then develop a better intuition of my data. In turn, this shapes the\nhypotheses and modeling choices that I make in the subsequent analysis stage.\n\n:::{.callout-warning}\n## Sorting and sampling\nI'm using a 1% random sample of my data here (see the `USING SAMPLE 1%`\nstatement).  Why? Because calculating deciles requires ranking your data and\nthis is expensive! To rank data, we first have to sort it (`ORDER`) and this\nrequires evaluating/comparing every single row in your dataset. In turn, this\nmeans that it's very hard to take shortcuts. (This is one reason why DuckDB's\noptimized query plan will always delay sorting until as late as possible; to\nonly sort on a smaller subset/aggregation of the data if possible.) FWIW,\nDuckDB's sorting algorithm is still\n[crazy fast](https://duckdb.org/2021/08/27/external-sorting.html).\nBut for data of this size, and where sorting on the full datset is unavoidable,\nI strongly recommend sampling first. Your general insights will almost certainly\nremain intact.\n:::\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbGetQuery(\n  con,\n  \"\n  WITH trip_deciles AS (\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      tip_amount,\n      trip_distance,\n      NTILE(10) OVER (ORDER BY trip_distance) AS decile\n    USING SAMPLE 1%\n  )\n  FROM trip_deciles\n  SELECT\n    decile,\n    AVG(trip_distance) AS mean_distance,\n    AVG(tip_amount) AS mean_tip\n  GROUP BY ALL\n  ORDER BY ALL\n  \"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   decile mean_distance  mean_tip\n1       1     0.4485001 0.5815993\n2       2     0.8077842 0.5140569\n3       3     1.0636530 0.5985021\n4       4     1.3244716 0.6870273\n5       5     1.6286108 0.7805147\n6       6     1.9959871 0.8992282\n7       7     2.4957121 1.0367072\n8       8     3.2551231 1.2510039\n9       9     4.7643520 1.6101116\n10     10    11.0504331 3.2807728\n```\n\n\n:::\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.query(\n  '''\n  WITH trip_deciles AS (\n    FROM 'nyc-taxi/**/*.parquet'\n    SELECT\n      tip_amount,\n      trip_distance,\n      NTILE(10) OVER (ORDER BY trip_distance) AS decile\n    USING SAMPLE 1%\n  )\n  FROM trip_deciles\n  SELECT\n    decile,\n    AVG(trip_distance) AS mean_distance,\n    AVG(tip_amount) AS mean_tip\n  GROUP BY ALL\n  ORDER BY ALL\n  '''\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n┌────────┬─────────────────────┬────────────────────┐\n│ decile │    mean_distance    │      mean_tip      │\n│ int64  │       double        │       double       │\n├────────┼─────────────────────┼────────────────────┤\n│      1 │ 0.44922310548259337 │ 0.5799620572865318 │\n│      2 │  0.8087209464724292 │ 0.5141380253494722 │\n│      3 │  1.0653553928716593 │ 0.6061122685320124 │\n│      4 │    1.32654500168768 │ 0.6880050396303666 │\n│      5 │  1.6308654663142164 │ 0.7849700881062599 │\n│      6 │  1.9978597283474906 │ 0.8918140923428113 │\n│      7 │    2.49924847821658 │  1.044309233114935 │\n│      8 │   3.258975663125616 │    1.2555553486423 │\n│      9 │   4.760698918160984 │   1.62306336819192 │\n│     10 │  11.029094432514512 │  3.272133126160228 │\n├────────┴─────────────────────┴────────────────────┤\n│ 10 rows                                 3 columns │\n└───────────────────────────────────────────────────┘\n```\n\n\n:::\n:::\n\n\n:::\n\n\n## Close connection\n\n::: {.panel-tabset}\n\n### R\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbDisconnect(con)\n```\n:::\n\n\nAgain, this step isn't strictly necessary since we instantiated our connection\nwith the `shutdown = TRUE` argument. But it's worth seeing in case you want to\nbe explicit.\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncon.close()\n```\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}